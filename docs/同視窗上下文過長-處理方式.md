# 同視窗上下文過長 — 處理方式

同一視窗聊久了會累積很多上下文，五段、十段後常常已經換話題，舊內容仍佔用 Token。可以這樣處理：

---

## 兩種主要做法

### 1. 自動（或手動）換新視窗

- **做法**：開一個新對話／新 session，從頭開始。
- **優點**：乾淨、沒有舊話題干擾，Token 從零算起。
- **缺點**：舊對話不在同一個 thread，要查之前說過的話得去舊視窗或靠記憶（MEMORY.md / memory_search）。
- **適合**：話題已經明顯切換、或你希望「這一段當作新的開始」時。

OpenClaw 本身不會「自動」幫你換視窗，需要你自己開新對話；若透過 Telegram／其他客戶端，可以約定「每 N 則或每換話題就開新 thread」來近似「自動換視窗」。

---

### 2. 在原視窗處理上下文：把 Token 控在一定數量、只保留最近幾筆

- **做法**：不換視窗，但**限制送進模型的內容**：只保留最近約 5～10 則對話（或對應的 token 上限），舊的捨棄或壓成摘要。
- **優點**：同一個 thread 延續，最近幾輪的上下文還在；搭配 **memory_search** 需要時可從 MEMORY 拉舊重點，不必整段歷史都送進去。
- **缺點**：模型「看不到」被壓掉或捨棄的原始對話，只能靠摘要或記憶搜尋補。
- **適合**：想留在同視窗、又要把每次請求的 Token 壓下來時。

OpenClaw 已支援這種做法，透過 **context pruning** 與 **compaction**：

| 機制 | 作用 | 可調項目 |
|------|------|----------|
| **contextPruning** | 每次請求前修剪：少保留舊的 tool 結果、只保留最近 N 則助理回覆 | `keepLastAssistants`（例如 2～5）、`ttl`、`softTrim.maxChars` |
| **compaction** | 當 context 快滿時，把**舊對話壓成摘要**，只留最近一段完整對話 | `reserveTokensFloor`（設大一點 = 更早壓縮、留給「新內容」的空間） |
| **pre-compaction memory flush** | 壓縮前先把重要內容寫進 MEMORY.md / memory/*.md | 壓縮後舊對話雖不見，重點仍在記憶裡，之後可用 memory_search 取出 |

所以「只保留最近約 5～10 筆對話」可以透過：  
**contextPruning.keepLastAssistants = 5**（或 10）再加上 **compaction** 的 **reserveTokensFloor** 來近似達成；詳細設定見 `每次溝通Token控制在4K或更少.md`、`用QMD記憶減少每次溝通的Token.md`。

---

## 建議怎麼選

- **話題已換、不想被舊話題影響** → 直接**開新視窗**最簡單。
- **想留在同視窗、又要控 Token** → 用**原視窗處理**：設好 contextPruning（只留最近 5～10 則）+ compaction + 重要的事寫進 MEMORY，需要時用 memory_search 補。

兩種可以並用：平常靠 pruning + compaction 控 token；覺得這一段該「重新開始」時就手動開新視窗。
