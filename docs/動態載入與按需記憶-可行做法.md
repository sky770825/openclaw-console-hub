# 動態載入上下文與按需記憶 — 有辦法解決嗎？

> 訴求：不要每輪都把 23K 上下文全送進去；改為「當前對話 + 必要系統指令 + 當前任務相關記憶」動態載入，且只有提到關鍵字、需要從 MEMORY 讀取時才把該部分記憶加入。  
> 結論：**部分已有、部分可做、部分需架構改動。**

---

## 一、OpenClaw 現有機制（已能省 token）

### 1.1 輕量 vs 完整 bootstrap（已實作）

OpenClaw **已經有**「依訊息類型選不同 bootstrap」的邏輯：

- **一般聊天**（你好、嗨、在嗎、早安、ok…）：用 **light bootstrap**，只帶 **IDENTITY + 精簡 USER**（約幾百 token），**不帶** MEMORY、AGENTS、SOUL、TOOLS、HEARTBEAT。
- **主題／任務／記憶**（幫我、記下來、查一下…）：用 **full bootstrap**，帶完整工作區檔案。

所以「動態載入」在 **一般閒聊 vs 正式任務** 這條軸上已經存在。

**你要做的：**

- 確認設定裡 **不要關掉** 這項（預設是開的）：
  ```json
  "agents": {
    "defaults": {
      "casualChatLightBootstrap": true
    }
  }
  ```
- 若設成 `false`，每輪都會用完整 bootstrap，token 就會多。

### 1.2 按需查記憶的工具（已存在）

在 **full 模式** 下，Agent 本來就有：

- **memory_search**：語意搜尋 MEMORY.md / memory/*.md，回傳符合的片段（path + 行號）。
- **memory_read_snippet**：依 path + 行號只讀取需要的段落，不讀整份檔案。

也就是說：**「按關鍵字去查、只把需要的片段拿進來」** 在「工具呼叫」這層已經支援；差別在於 **full 時整份 MEMORY.md 還是會先被放進 bootstrap**，所以輸入 token 仍會包含整份 MEMORY。

---

## 二、目前限制（為何會覺得「沒辦法」）

- **誰決定送什麼給模型：** 是 **OpenClaw 的 runner**（例如 `pi-embedded-runner/run/attempt.ts`），不是 Agent 自己。Runner 在每輪呼叫前會：
  - 用 `isCasualChat(prompt)` 決定 light vs full；
  - 用 `resolveBootstrapContextForRun({ bootstrapMode })` 決定要載入哪些工作區檔案；
  - 把這些檔案內容 + 對話歷史一起組成送給模型的 context。
- **full 時會帶入的：** AGENTS、SOUL、TOOLS、IDENTITY、USER、HEARTBEAT、BOOTSTRAP、**MEMORY.md** 等（工作區裡有的都會被讀進來）。  
  所以只要 MEMORY.md 很大，full 時 23K 裡就會有一大塊是 MEMORY。

Agent **不能**自己說「這輪只送我的回覆、下一輪再送記憶」；它只能：

- 在 **light 時** 少送很多東西（系統已做），
- 在 **full 時** 用 memory_search / memory_read_snippet **少讀一點到回覆裡**，但 **輸入** 仍包含整份 MEMORY。

---

## 三、在現有架構下能做的事

### 3.1 確保「一般聊天」真的走 light（必做）

- 設定保留 `casualChatLightBootstrap: true`（或不要設成 false）。
- 這樣「你好、嗨、ok」等就不會帶 MEMORY/TOOLS，token 立刻少很多。

### 3.2 把 MEMORY.md 壓到「索引 + 極短摘要」（必做）

- **MEMORY.md 只放：** 關鍵字索引、對應區塊標題或路徑、最近一兩句摘要。
- **詳細內容** 放到 Notion 或 MEMORY_FULL.md（且 **不要** 把 MEMORY_FULL 放進工作區 bootstrap 會讀的檔名，或不要放在預設會載入的目錄），需要時用 **memory_search**（若你有接 Notion 就用 Notion skill / 工具）按需拉。
- 這樣即使 full 時整份 MEMORY.md 被送進去，token 也小。

### 3.3 用 `agent:bootstrap` 勾子排除或縮短 MEMORY（進階）

OpenClaw 有 **agent:bootstrap** 內部勾子，在組裝送給模型的 bootstrap **之前** 會呼叫，且可以 **改寫要載入的檔案清單**。

- **做法一：完全不帶 MEMORY.md**  
  在勾子裡把 `context.bootstrapFiles` 中名為 `MEMORY.md` 的項目拿掉。  
  效果：full 時也不會把 MEMORY 送進模型，模型要記憶時必須依賴 **memory_search / memory_read_snippet**（或你提供的 Notion 工具）按需查。
- **做法二：只帶「索引版」**  
  在勾子裡把 MEMORY.md 的 `content` 換成你事先準備的「只有關鍵字 + 路徑」的短版（例如前 500 字），再送進 context。

這需要寫一個 **plugin 或載入 hook 的腳本**，在 Gateway 啟動時 `registerInternalHook("agent:bootstrap", ...)`，在 handler 裡改 `event.context.bootstrapFiles`。  
（OpenClaw 的 plugin 可註冊 internal hook；見 `src/plugins/registry.ts`、`src/hooks/loader.ts`。）

---

## 四、若要做到「完全按需、不送整份 MEMORY」

理想情況是：

- 每輪送給模型的「輸入」裡 **從來不包含** 整份 MEMORY，只包含：
  - 系統提示（身份、規則）、
  - 當前對話、
  - 必要時才插入「本輪從 memory_search / Notion 取回的那幾段」。
- 這代表「組裝 context」的邏輯要變成：  
  先決定這輪要不要查記憶 → 若要，先跑 memory_search（或呼叫 Notion）→ 只把**查到的片段**當成額外 context 插進去，再送模型。

這在目前 OpenClaw 裡 **沒有現成流程**：現在是「先定 bootstrap（含整份 MEMORY）→ 一次送給模型」。要改成上述流程，需要 **runner / 組裝 context 的程式** 支援「可選的記憶注入階段」（例如兩階段：先輕量問「要不要記憶？」或直接根據關鍵字查，再組第二包 context）。這屬於 **架構層級的擴充**，不是只調設定或只寫 Agent 指令就能達成。

---

## 五、建議你現在就做的順序

1. **確認 light bootstrap 有開**  
   `agents.defaults.casualChatLightBootstrap` 不要設成 `false`。
2. **精簡 MEMORY.md**  
   只留索引與極短摘要；詳細改放 Notion 或 MEMORY_FULL，並用 memory_search / Notion 工具按需讀。
3. **（可選）**  
   若你或有人能寫 OpenClaw plugin，用 **agent:bootstrap** 勾子把 MEMORY.md 從 bootstrap 拿掉或換成索引版，這樣 full 時也不會把整份 MEMORY 送進去，更接近「按需記憶」。

這樣在 **不改 OpenClaw 核心** 的前提下，已經能明顯降低 token，並讓「按需調用記憶」盡量透過現有工具（memory_search、Notion）與精簡 MEMORY.md 來達成。若未來 OpenClaw 官方或社群實作「可選的記憶注入階段」，再可以進一步逼近你要的「完全動態組裝輸入」。

---

## 相關文件

- [記憶與對話-一般聊天輕量模式設計](./記憶與對話-一般聊天輕量模式設計.md)
- [記憶-自動化寫入設計](./記憶-自動化寫入設計.md)
- [記憶索引-主題與命中率設計](./記憶索引-主題與命中率設計.md)
- OpenClaw 原始碼：`src/agents/casual-chat-classifier.ts`、`src/agents/bootstrap-files.ts`、`src/agents/pi-embedded-runner/run/attempt.ts`、`src/agents/bootstrap-hooks.ts`
