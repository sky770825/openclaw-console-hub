#!/usr/bin/env python3
"""
Ollama æœ¬æ©Ÿé€£ç·š â€” ç¬¬äºŒå€‹ Telegram Bot
èˆ‡ ollama_monitor_bot å…±ç”¨åŒä¸€å¥— Ollama é€£ç·šï¼ˆollama_clientï¼‰ï¼Œ
ä½¿ç”¨ä¸åŒçš„ Bot Tokenï¼Œå¾ ollama_bot2.env è®€å–è¨­å®šã€‚
"""

import os
import re
import subprocess
import sys
import time
import logging
from pathlib import Path
from typing import Optional

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, KeyboardButton, ReplyKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackQueryHandler, filters, ContextTypes

ENV_FILE = Path(__file__).parent / "ollama_bot2.env"

import ollama_client

ollama_client.load_env(ENV_FILE)

# å¾ ollama_bot2.env è®€å–è¨­å®š
def _load_env_var(key: str, default: str = "") -> str:
    val = os.getenv(key, default)
    if val:
        return val
    if ENV_FILE.exists():
        for line in ENV_FILE.read_text(encoding="utf-8").strip().splitlines():
            if "=" in line and not line.strip().startswith("#"):
                k, v = line.split("=", 1)
                k, v = k.strip(), v.strip().strip("'\"")
                if k == key and v:
                    return v
    return default

TELEGRAM_BOT_TOKEN = _load_env_var("TELEGRAM_BOT_TOKEN")
_allowed_raw = _load_env_var("ALLOWED_USER_IDS")
ALLOWED_USER_IDS_SET = frozenset(x.strip() for x in _allowed_raw.split(",") if x.strip()) if _allowed_raw.strip() else None  # None = æ‰€æœ‰äººå¯åŸ·è¡Œ
MSG_MAX = 4000

LOG_DIR = Path(__file__).parent
LOG_FILE = LOG_DIR / "ollama_bot2.log"
KNOWLEDGE_FILE = LOG_DIR / "knowledge" / "knowledge_base.md"
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
    handlers=[
        logging.FileHandler(LOG_FILE, encoding="utf-8"),
        logging.StreamHandler(sys.stdout),
    ],
)
logger = logging.getLogger(__name__)

# é•·æœŸè¨˜æ†¶ï¼šæˆé•·å‹ï¼Œæ¯ç”¨æˆ¶ä¸€å€‹ memory.yaml
MEMORY_DIR = Path(__file__).parent / "memories"
MEMORY_MAX_LINES = 25  # è¶…éæ­¤è¡Œæ•¸æ™‚ï¼Œç”±æ¨¡å‹ consolidating æ¿ƒç¸®
MEMORY_SYSTEM = """è«‹é è¨­ä½¿ç”¨ç¹é«”ä¸­æ–‡å›è¦†ã€‚é•·ç¯‡å›è¦†æ™‚è«‹å‹¿ä½¿ç”¨ **ã€##ã€* ç­‰ markdown ç¬¦è™Ÿï¼Œç”¨ç´”æ–‡å­—å³å¯ã€‚

ä»¥ä¸‹æ˜¯ä½ çš„çŸ¥è­˜åº«ï¼ˆå›ç­”æ™‚å¯åƒè€ƒï¼Œå„ªå…ˆæ–¼çŒœæ¸¬ï¼‰ï¼š
{knowledge}

ä»¥ä¸‹æ˜¯ä½ çš„é•·æœŸè¨˜æ†¶ï¼ˆæˆé•·å‹ï¼Œæœƒéš¨å°è©±æ…¢æ…¢ç´¯ç©èˆ‡ç²¾ç…‰ï¼‰ï¼š
{memory}

è‹¥æœ¬æ¬¡å°è©±æœ‰å€¼å¾—é•·æœŸè¨˜ä½çš„å…§å®¹ï¼ˆç”¨æˆ¶åå¥½ã€é‡è¦äº‹å¯¦ã€ç´„å®šï¼‰ï¼Œè«‹åœ¨å›è¦†**æœ€å¾Œ**åŠ ä¸Šï¼š
[memory_patch]
- äº‹å¯¦1
- äº‹å¯¦2
[/memory_patch]

è‹¥ç„¡éœ€æ›´æ–°è¨˜æ†¶ï¼Œä¸è¦åŠ  memory_patchã€‚å›è¦†æ™‚ä¿æŒè‡ªç„¶ï¼Œè¨˜æ†¶å€å¡Šæœƒè‡ªå‹•è™•ç†ã€‚"""

CONSOLIDATE_PROMPT = """è«‹å°‡ä»¥ä¸‹é•·æœŸè¨˜æ†¶æ¿ƒç¸®æˆæœ€ç²¾è¯çš„é—œéµäº‹å¯¦ï¼ˆå»é‡ã€åˆä½µç›¸ä¼¼ã€ä¿ç•™é‡è¦è³‡è¨Šï¼Œæ§åˆ¶åœ¨ 15 æ¢ä»¥å…§ï¼‰ã€‚åªè¼¸å‡º [memory_patch] å€å¡Šï¼Œæ ¼å¼ï¼š
[memory_patch]
- äº‹å¯¦1
- äº‹å¯¦2
[/memory_patch]"""


KNOWLEDGE_AUTO_FILE = LOG_DIR / "knowledge" / "knowledge_auto.md"
KNOWLEDGE_MAX_CHARS = 10000  # çŸ¥è­˜åº«ç¸½é•·ä¸Šé™ï¼Œé¿å… context éå¤§æ‹–æ…¢å›è¦†


def _load_knowledge() -> str:
    """è®€å–çŸ¥è­˜åº«ï¼ˆä¾›æ³¨å…¥ system promptï¼‰ï¼šknowledge_base.md + knowledge_auto.mdã€‚æœ‰é•·åº¦ä¸Šé™ã€‚"""
    parts = []
    total = 0
    if KNOWLEDGE_FILE.exists():
        try:
            c = KNOWLEDGE_FILE.read_text(encoding="utf-8").strip()
            if c and total + len(c) <= KNOWLEDGE_MAX_CHARS:
                parts.append(c)
                total += len(c)
        except Exception:
            pass
    if KNOWLEDGE_AUTO_FILE.exists() and total < KNOWLEDGE_MAX_CHARS:
        try:
            c = KNOWLEDGE_AUTO_FILE.read_text(encoding="utf-8").strip()
            if c:
                remainder = KNOWLEDGE_MAX_CHARS - total - 50
                if len(c) > remainder:
                    c = c[:remainder] + "\n...(å·²æˆªæ–·)"
                parts.append("\n---\n" + c)
        except Exception:
            pass
    if not parts:
        return "(å°šç„¡çŸ¥è­˜åº«ï¼Œå¯æ–°å¢ knowledge/knowledge_base.md)"
    return "\n".join(parts)


def _load_memory(user_id: int) -> str:
    """è®€å–è©²ç”¨æˆ¶çš„é•·æœŸè¨˜æ†¶ã€‚"""
    MEMORY_DIR.mkdir(exist_ok=True)
    f = MEMORY_DIR / f"{user_id}.yaml"
    if not f.exists():
        return "(å°šç„¡é•·æœŸè¨˜æ†¶)"
    try:
        return f.read_text(encoding="utf-8").strip() or "(å°šç„¡é•·æœŸè¨˜æ†¶)"
    except Exception:
        return "(å°šç„¡é•·æœŸè¨˜æ†¶)"


def _clear_memory(user_id: int) -> None:
    """æ¸…é™¤è©²ç”¨æˆ¶çš„é•·æœŸè¨˜æ†¶ã€‚"""
    f = MEMORY_DIR / f"{user_id}.yaml"
    if f.exists():
        f.unlink()
        logger.info("å·²æ¸…é™¤ user_id=%s çš„è¨˜æ†¶", user_id)


def _save_memory(user_id: int, new_facts: list[str]) -> None:
    """å°‡æ–°äº‹å¯¦é™„åŠ åˆ°è©²ç”¨æˆ¶çš„é•·æœŸè¨˜æ†¶ã€‚"""
    MEMORY_DIR.mkdir(exist_ok=True)
    f = MEMORY_DIR / f"{user_id}.yaml"
    existing = []
    if f.exists():
        try:
            for line in f.read_text(encoding="utf-8").splitlines():
                if line.strip().startswith("- "):
                    existing.append(line.strip())
        except Exception:
            pass
    seen = set(existing)
    for x in new_facts:
        x = x.strip()
        if x and x not in seen:
            existing.append(f"- {x}" if not x.startswith("-") else x)
            seen.add(x)
    f.write_text("\n".join(existing) + "\n", encoding="utf-8")


def _consolidate_memory(user_id: int, model: str) -> bool:
    """ç•¶è¨˜æ†¶éé•·æ™‚ï¼Œç”±æ¨¡å‹æ¿ƒç¸®æˆç²¾è¯ï¼Œå½¢æˆæˆé•·å‹è¨˜æ†¶ã€‚"""
    f = MEMORY_DIR / f"{user_id}.yaml"
    if not f.exists():
        return False
    content = f.read_text(encoding="utf-8")
    lines = [l for l in content.splitlines() if l.strip().startswith("- ")]
    if len(lines) < MEMORY_MAX_LINES:
        return False
    logger.info("è¨˜æ†¶éé•· (%d è¡Œ)ï¼Œè§¸ç™¼ consolidating", len(lines))
    full_memory = "\n".join(lines)
    messages = [
        {"role": "system", "content": CONSOLIDATE_PROMPT},
        {"role": "user", "content": full_memory},
    ]
    ok, reply = ollama_client.ask_ollama_messages(messages, model)
    if not ok:
        return False
    _, facts = _parse_memory_patch(reply)
    if facts:
        lines = [f"- {x}" if not str(x).strip().startswith("-") else str(x).strip() for x in facts]
        f.write_text("\n".join(lines) + "\n", encoding="utf-8")
        logger.info("å·² consolidating è¨˜æ†¶ç‚º %d æ¢", len(facts))
        return True
    return False


def _strip_markdown(reply: str) -> str:
    """ç§»é™¤å¸¸è¦‹ markdown ç¬¦è™Ÿï¼ˆ**ã€##ã€* ç­‰ï¼‰ï¼Œä¿ç•™ç´”æ–‡å­—ã€‚"""
    s = re.sub(r"\*\*([^*]+)\*\*", r"\1", reply)  # **bold** -> bold
    s = re.sub(r"\*([^*]+)\*", r"\1", s)          # *italic* -> italic
    s = re.sub(r"^#+\s*", "", s, flags=re.MULTILINE)  # ## title -> title
    return s.strip()


def _parse_memory_patch(reply: str) -> tuple[str, list[str]]:
    """å¾å›è¦†ä¸­è§£æ [memory_patch]...[/memory_patch]ï¼Œå›å‚³ (ä¹¾æ·¨å›è¦†, æ–°äº‹å¯¦åˆ—è¡¨)ã€‚"""
    m = re.search(r"\[memory_patch\](.*?)\[/memory_patch\]", reply, re.DOTALL | re.IGNORECASE)
    if not m:
        return reply.strip(), []
    block = m.group(1).strip()
    facts = []
    for line in block.splitlines():
        line = line.strip()
        if line.startswith("-"):
            s = line[1:].strip()
            if s:
                facts.append(s)
        elif line:
            facts.append(line)
    clean = (reply[: m.start()] + reply[m.end() :]).strip()
    clean = re.sub(r"\n{3,}", "\n\n", clean)  # å¤šé¤˜ç©ºè¡Œ
    return clean, facts


# åº•éƒ¨å›ºå®šé¸å–®æŒ‰éˆ•ï¼ˆåƒ OpenClaw ä¸€æ¨£å¯é»é¸ï¼‰
MENU_KEYBOARD = ReplyKeyboardMarkup(
    [
        [KeyboardButton("ğŸ“Š ç‹€æ…‹"), KeyboardButton("ğŸ“‹ åˆ‡æ›æ¨¡å‹")],
        [KeyboardButton("ğŸ”„ é‡å•Ÿ OpenClaw"), KeyboardButton("ğŸ”„ é‡å•Ÿ Ollama")],
        [KeyboardButton("ğŸ“‹ Gateway æ—¥èªŒ"), KeyboardButton("ğŸ” æª¢æŸ¥ Port")],
        [KeyboardButton("ğŸ“‹ æœå‹™åˆ—è¡¨"), KeyboardButton("ğŸ—‘ æ¸…é™¤è¨˜æ†¶")],
    ],
    resize_keyboard=True,
    is_persistent=True,
)


async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
    logger.error("è™•ç†æ›´æ–°æ™‚ç™¼ç”ŸéŒ¯èª¤: %s", context.error, exc_info=context.error)


async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    logger.info("æ”¶åˆ° /start from @%s (id=%s)", user.username, user.id)
    await update.message.reply_text(
        "ğŸ¤– Ollama Bot #2\n\n"
        "é€£æ¥æœ¬æ©Ÿ Ollamaï¼Œå¯èˆ‡æœ¬åœ°æ¨¡å‹å°è©±\n\n"
        "å¯ä½¿ç”¨ä¸‹æ–¹æŒ‰éˆ•å¿«é€Ÿæ“ä½œï¼Œæˆ–ç›´æ¥ç™¼é€è¨Šæ¯èˆ‡ AI å°è©±ã€‚",
        reply_markup=MENU_KEYBOARD,
    )


async def cmd_model(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if context.args:
        new_model = context.args[0].strip()
        context.user_data["ollama_model"] = new_model
        logger.info("ç”¨æˆ¶åˆ‡æ›æ¨¡å‹ç‚º %s", new_model)
        await update.message.reply_text(f"âœ… å·²åˆ‡æ›æ¨¡å‹ç‚º: {new_model}")
    else:
        ok, names = ollama_client.list_models()
        current = context.user_data.get("ollama_model", ollama_client.OLLAMA_MODEL)
        if ok and names:
            keyboard = [
                [InlineKeyboardButton(n, callback_data=f"model:{n}")] for n in names
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await update.message.reply_text(
                f"ç›®å‰æ¨¡å‹: {current}\né»é¸ä¸‹æ–¹æŒ‰éˆ•åˆ‡æ›ï¼š",
                reply_markup=reply_markup,
            )
        else:
            await update.message.reply_text(
                f"ç›®å‰æ¨¡å‹: {current}\nä½¿ç”¨ /model <åç¨±> åˆ‡æ›\nï¼ˆOllama æœªé€£ç·šæˆ–ç„¡æ¨¡å‹ï¼‰"
            )


async def cb_model(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """è™•ç† inline æŒ‰éˆ•ï¼šåˆ‡æ›æ¨¡å‹"""
    query = update.callback_query
    await query.answer()
    if not query.data or not query.data.startswith("model:"):
        return
    new_model = query.data.replace("model:", "", 1)
    context.user_data["ollama_model"] = new_model
    logger.info("ç”¨æˆ¶é»æ“Šåˆ‡æ›æ¨¡å‹ç‚º %s", new_model)
    await query.edit_message_text(f"âœ… å·²åˆ‡æ›æ¨¡å‹ç‚º: {new_model}")


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not update.message or not update.message.text:
        return
    text = update.message.text.strip()
    if not text:
        return
    # è™•ç†é¸å–®æŒ‰éˆ•é»æ“Š
    if text == "ğŸ“Š ç‹€æ…‹":
        ok, msg = ollama_client.check_ollama_status()
        await update.message.reply_text(msg)
        return
    if text == "ğŸ“‹ åˆ‡æ›æ¨¡å‹":
        ok, names = ollama_client.list_models()
        current = context.user_data.get("ollama_model", ollama_client.OLLAMA_MODEL)
        if ok and names:
            keyboard = [[InlineKeyboardButton(n, callback_data=f"model:{n}")] for n in names]
            await update.message.reply_text(
                f"ç›®å‰æ¨¡å‹: {current}\né»é¸ä¸‹æ–¹æŒ‰éˆ•åˆ‡æ›ï¼š",
                reply_markup=InlineKeyboardMarkup(keyboard),
            )
        else:
            await update.message.reply_text(
                f"ç›®å‰æ¨¡å‹: {current}\nä½¿ç”¨ /model <åç¨±> åˆ‡æ›\nï¼ˆOllama æœªé€£ç·šæˆ–ç„¡æ¨¡å‹ï¼‰"
            )
        return
    if text == "ğŸ”„ é‡å•Ÿ OpenClaw":
        user = update.effective_user
        if not _can_exec(user.id):
            await update.message.reply_text("âŒ ä½ æ²’æœ‰æ¬Šé™åŸ·è¡Œæ­¤æŒ‡ä»¤")
            return
        msg = await update.message.reply_text("â³ æ­£åœ¨å®Œæ•´é‡å•Ÿ OpenClaw Gateway...")
        ok, reply_text = _do_restart_openclaw()
        await msg.edit_text(reply_text)
        return
    # é€éæ–‡å­—è§¸ç™¼ openclaw gateway restartï¼ˆéœ€æ¬Šé™ï¼‰
    if "openclaw gateway restart" in text.lower() or "openclaw gateway é‡å•Ÿ" in text:
        user = update.effective_user
        if not _can_exec(user.id):
            await update.message.reply_text("âŒ ä½ æ²’æœ‰æ¬Šé™åŸ·è¡Œæ­¤æŒ‡ä»¤")
            return
        msg = await update.message.reply_text("â³ åŸ·è¡Œ openclaw gateway restart...")
        ok, out = _run_openclaw_gateway_restart()
        await msg.edit_text(out)
        return
    if text == "ğŸ”„ é‡å•Ÿ Ollama":
        user = update.effective_user
        if not _can_exec(user.id):
            await update.message.reply_text("âŒ ä½ æ²’æœ‰æ¬Šé™åŸ·è¡Œæ­¤æŒ‡ä»¤")
            return
        msg = await update.message.reply_text("â³ æ­£åœ¨é‡å•Ÿ Ollama...")
        ok, reply_text = _do_restart_ollama()
        await msg.edit_text(reply_text)
        return
    if text == "ğŸ“‹ Gateway æ—¥èªŒ":
        user = update.effective_user
        if not _can_exec(user.id):
            await update.message.reply_text("âŒ ä½ æ²’æœ‰æ¬Šé™åŸ·è¡Œæ­¤æŒ‡ä»¤")
            return
        await update.message.reply_text(_truncate(_get_gateway_logs()))
        return
    if text == "ğŸ” æª¢æŸ¥ Port":
        user = update.effective_user
        if not _can_exec(user.id):
            await update.message.reply_text("âŒ ä½ æ²’æœ‰æ¬Šé™åŸ·è¡Œæ­¤æŒ‡ä»¤")
            return
        txt = _check_port()
        await update.message.reply_text(txt)
        return
    if text == "ğŸ“‹ æœå‹™åˆ—è¡¨":
        user = update.effective_user
        if not _can_exec(user.id):
            await update.message.reply_text("âŒ ä½ æ²’æœ‰æ¬Šé™åŸ·è¡Œæ­¤æŒ‡ä»¤")
            return
        await update.message.reply_text(_list_services())
        return
    if text == "ğŸ—‘ æ¸…é™¤è¨˜æ†¶":
        user = update.effective_user
        _clear_memory(user.id)
        if "chat_history" in context.user_data:
            del context.user_data["chat_history"]
        await update.message.reply_text("âœ… å·²æ¸…é™¤ä½ çš„é•·æœŸè¨˜æ†¶èˆ‡å°è©±æ­·ç¨‹")
        return
    # ä»»å‹™æ¿è§¸ç™¼ï¼ˆéœ€æ¬Šé™ï¼‰
    task_board_result = _try_task_board_command(text, update.effective_user)
    if task_board_result is not None:
        await update.message.reply_text(_truncate(task_board_result))
        return
    # ä¸€èˆ¬è¨Šæ¯ï¼šè½‰çµ¦ Ollamaï¼ˆå«é•·æœŸè¨˜æ†¶èˆ‡çŸ­æœŸå°è©±æ­·ç¨‹ï¼‰
    user = update.effective_user
    model = context.user_data.get("ollama_model", ollama_client.OLLAMA_MODEL)
    logger.info("æ”¶åˆ°è¨Šæ¯, æ¨¡å‹=%s: %s...", model, text[:50])
    status = await update.message.reply_text("â³ æœ¬æ©Ÿ Ollama è™•ç†ä¸­...")
    memory = _load_memory(user.id)
    knowledge = _load_knowledge()
    history = context.user_data.get("chat_history", [])
    messages = [
        {"role": "system", "content": MEMORY_SYSTEM.format(memory=memory, knowledge=knowledge)},
        *history[-6:],
        {"role": "user", "content": text},
    ]
    num_predict, num_ctx, temperature = ollama_client._speed_options(model)
    full_reply = []
    last_edit = 0
    edit_interval = 0.8  # æ›´æ–°é–“éš”ï¼ˆç§’ï¼‰ï¼Œé¿å… Telegram rate limit
    first_edit_done = False
    for ok, chunk in ollama_client.ask_ollama_messages_stream(
        messages, model, num_ctx=num_ctx or 4096, num_predict=num_predict, temperature=temperature
    ):
        if not ok:
            await status.edit_text(f"âŒ {chunk}")
            return
        if chunk:
            full_reply.append(chunk)
            now = time.time()
            # æœ‰è¶³å¤ å…§å®¹æ™‚ç«‹å³åšé¦–æ¬¡æ›´æ–°ï¼Œä¹‹å¾ŒæŒ‰é–“éš”æ›´æ–°
            should_edit = (not first_edit_done and len(full_reply) >= 1) or (
                first_edit_done and now - last_edit >= edit_interval
            )
            if should_edit:
                partial = "".join(full_reply)
                try:
                    suffix = "\n\nâ³ ..." if chunk else ""
                    await status.edit_text(_truncate(_strip_markdown(partial)) + suffix)
                    last_edit = now
                    first_edit_done = True
                except Exception:
                    pass
    reply = "".join(full_reply)
    if not reply:
        await status.edit_text("âŒ æ¨¡å‹ç„¡å›è¦†")
        return
    clean_reply, facts = _parse_memory_patch(reply)
    if facts:
        _save_memory(user.id, facts)
        logger.info("å·²å¯«å…¥ memory_patch: %s", facts[:3])
        _consolidate_memory(user.id, model)  # æˆé•·å‹ï¼šéé•·æ™‚æ¿ƒç¸®
    clean_reply = _strip_markdown(clean_reply)
    history.append({"role": "user", "content": text})
    history.append({"role": "assistant", "content": clean_reply})
    context.user_data["chat_history"] = history[-14:]
    await status.edit_text(_truncate(clean_reply))


def _can_exec(user_id: int) -> bool:
    if ALLOWED_USER_IDS_SET is None:
        return True
    return str(user_id) in ALLOWED_USER_IDS_SET


def _truncate(txt: str, max_len: int = MSG_MAX) -> str:
    """æˆªæ–·éé•·æ–‡å­—ï¼Œç¬¦åˆ Telegram é™åˆ¶ã€‚"""
    if len(txt) <= max_len:
        return txt
    return txt[:max_len] + "\n\n...(å·²æˆªæ–·)"


GATEWAY_PORT = 18789


TASK_BOARD_SCRIPT = LOG_DIR / "scripts" / "task-board-api.sh"
TASK_BOARD_API_BASE = os.getenv("TASK_BOARD_API_BASE", "http://localhost:3009")


def _run_task_board(cmd: str, *args: str) -> str:
    """åŸ·è¡Œ task-board-api.shï¼Œå›å‚³è¼¸å‡ºã€‚"""
    if not TASK_BOARD_SCRIPT.exists():
        return f"âŒ æ‰¾ä¸åˆ°è…³æœ¬: {TASK_BOARD_SCRIPT}"
    try:
        env = {**os.environ, "TASK_BOARD_API_BASE": TASK_BOARD_API_BASE}
        r = subprocess.run(
            [str(TASK_BOARD_SCRIPT), cmd, *args],
            capture_output=True,
            text=True,
            timeout=15,
            cwd=str(LOG_DIR),
            env=env,
        )
        out = (r.stdout or r.stderr or "").strip()
        if r.returncode != 0 and out:
            return f"âŒ {out}"
        return out or "(ç„¡è¼¸å‡º)"
    except subprocess.TimeoutExpired:
        return "âŒ åŸ·è¡Œé€¾æ™‚"
    except Exception as e:
        return f"âŒ éŒ¯èª¤: {e}"


def _try_task_board_command(text: str, user) -> Optional[str]:
    """
    è‹¥è¨Šæ¯ç¬¦åˆä»»å‹™æ¿æŒ‡ä»¤å‰‡åŸ·è¡Œä¸¦å›å‚³çµæœï¼Œå¦å‰‡å›å‚³ Noneã€‚
    éœ€ _can_exec æ¬Šé™ã€‚
    """
    if not _can_exec(user.id):
        return None
    t = text.strip().lower()
    # list-tasks
    if t in ("list-tasks", "åˆ—ä»»å‹™", "ä»»å‹™æ¿ åˆ—è¡¨", "ä»»å‹™æ¿ åˆ—ä»»å‹™", "ä»»å‹™åˆ—è¡¨"):
        return _run_task_board("list-tasks")
    # list-runs
    if t in ("list-runs", "åŸ·è¡Œç´€éŒ„", "ä»»å‹™æ¿ åŸ·è¡Œç´€éŒ„", "runs"):
        return _run_task_board("list-runs")
    # run-task <id>
    run_prefixes = ("run-task ", "åŸ·è¡Œä»»å‹™ ", "run task ", "ä»»å‹™æ¿ åŸ·è¡Œ ")
    for prefix in run_prefixes:
        if t.startswith(prefix):
            task_id = text[len(prefix) :].strip().split()[0] if len(text) > len(prefix) else ""
            if not task_id:
                return "âŒ è«‹æä¾›ä»»å‹™ IDï¼Œä¾‹å¦‚ï¼šrun-task t1 æˆ– åŸ·è¡Œä»»å‹™ task-xxx"
            return _run_task_board("run-task", task_id)
    return None


def _run_openclaw_gateway_restart() -> tuple[bool, str]:
    """åŸ·è¡Œ openclaw gateway restart æŒ‡ä»¤ã€‚"""
    try:
        r = subprocess.run(
            ["openclaw", "gateway", "restart"],
            capture_output=True,
            text=True,
            timeout=30,
            env={**os.environ, "PATH": os.environ.get("PATH", "/usr/local/bin:/usr/bin:/bin")},
        )
        out = (r.stdout or "").strip() or (r.stderr or "").strip()
        if r.returncode == 0:
            return True, f"âœ… {out}"
        return False, f"âŒ exit {r.returncode}\n{out}"
    except FileNotFoundError:
        return False, "âŒ æ‰¾ä¸åˆ° openclaw æŒ‡ä»¤ï¼Œè«‹ç¢ºèªå·²å®‰è£"
    except subprocess.TimeoutExpired:
        return False, "âŒ åŸ·è¡Œé€¾æ™‚"
    except Exception as e:
        return False, f"âŒ éŒ¯èª¤: {e}"


def _do_restart_openclaw() -> tuple[bool, str]:
    """å®Œæ•´é‡å•Ÿ OpenClaw Gatewayï¼šå…ˆåœæ‰èˆŠæœå‹™ï¼Œå†å•Ÿå‹•ã€‚"""
    plist = Path.home() / "Library/LaunchAgents/ai.openclaw.gateway.plist"
    if not plist.exists():
        return False, f"âŒ æ‰¾ä¸åˆ° plist: {plist}"
    try:
        uid = subprocess.run(["/usr/bin/id", "-u"], capture_output=True, text=True, timeout=5).stdout.strip()
        service_name = f"gui/{uid}/ai.openclaw.gateway"
        
        # 1. å…ˆåœæ‰æœå‹™ï¼ˆå¦‚æœæ­£åœ¨é‹è¡Œï¼‰
        subprocess.run(
            ["/bin/launchctl", "bootout", service_name],
            capture_output=True, timeout=10
        )
        logger.info("å·²åŸ·è¡Œ bootout %s", service_name)
        time.sleep(2)
        
        # 2. æ¸…ç†æ®˜ç•™é€²ç¨‹
        subprocess.run(["/usr/bin/pkill", "-9", "-f", "openclaw-gateway"], capture_output=True, timeout=5)
        try:
            out = subprocess.run(
                ["/usr/sbin/lsof", "-ti", str(GATEWAY_PORT)],
                capture_output=True, text=True, timeout=5,
            )
            if out.returncode == 0 and out.stdout.strip():
                for pid in out.stdout.strip().split():
                    subprocess.run(["/bin/kill", "-9", pid], capture_output=True, timeout=3)
                logger.info("å·²æ¸…ç† port %s é€²ç¨‹", GATEWAY_PORT)
        except Exception:
            pass
        time.sleep(2)
        
        # 3. é‡æ–°è¼‰å…¥ä¸¦å•Ÿå‹•
        r = subprocess.run(
            ["/bin/launchctl", "bootstrap", f"gui/{uid}", str(plist)],
            capture_output=True, text=True, timeout=30,
        )
        logger.info("bootstrap exit=%s stderr=%s", r.returncode, (r.stderr or "")[:200])
        if r.returncode != 0:
            err = (r.stderr or "").strip() or (r.stdout or "").strip()
            return False, f"âš ï¸ bootstrap å¤±æ•—ï¼š\n{err}"
        
        time.sleep(3)
        
        # 4. é©—è­‰æ˜¯å¦æˆåŠŸå•Ÿå‹•
        check = subprocess.run(
            ["/bin/launchctl", "print", service_name],
            capture_output=True, text=True, timeout=5,
        )
        if "state = running" in check.stdout:
            return True, "âœ… OpenClaw Gateway å·²é‡å•ŸæˆåŠŸ"
        return True, "âš ï¸ é‡å•ŸæŒ‡ä»¤å·²ç™¼é€ï¼Œè«‹ç¨å¾Œæª¢æŸ¥ç‹€æ…‹"
    except subprocess.TimeoutExpired:
        return False, "âŒ åŸ·è¡Œé€¾æ™‚"
    except Exception as e:
        logger.exception("restart_openclaw å¤±æ•—")
        return False, f"âŒ éŒ¯èª¤: {str(e)}"


def _do_restart_ollama() -> tuple[bool, str]:
    """é‡å•Ÿ Ollama serveï¼ˆLaunchAgentï¼‰ã€‚"""
    for label in ("ai.ollama.serve", "com.ollama.server"):
        plist = Path.home() / f"Library/LaunchAgents/{label}.plist"
        if not plist.exists():
            continue
        try:
            uid = subprocess.run(["id", "-u"], capture_output=True, text=True, timeout=5).stdout.strip()
            r = subprocess.run(
                ["launchctl", "kickstart", "-k", f"gui/{uid}/{label}"],
                capture_output=True,
                text=True,
                timeout=30,
            )
            if r.returncode == 0:
                return True, f"âœ… Ollama ({label}) å·²é‡å•Ÿ"
            return False, f"âš ï¸ é‡å•Ÿå¤±æ•—ï¼š{(r.stderr or r.stdout or '').strip()}"
        except Exception as e:
            return False, f"âŒ éŒ¯èª¤: {str(e)}"
    return False, "âŒ æ‰¾ä¸åˆ° Ollama LaunchAgent (ai.ollama.serve æˆ– com.ollama.server)"


def _get_gateway_logs(lines: int = 30) -> str:
    """å–å¾— Gateway éŒ¯èª¤æ—¥èªŒæœ€å¾Œ N è¡Œã€‚"""
    p = Path.home() / ".openclaw/logs/gateway.err.log"
    if not p.exists():
        return "ç„¡ gateway.err.log"
    try:
        out = subprocess.run(
            ["tail", "-n", str(lines), str(p)],
            capture_output=True,
            text=True,
            timeout=5,
        )
        return out.stdout.strip() or "(ç©ºç™½)"
    except Exception as e:
        return f"è®€å–å¤±æ•—: {e}"


def _check_port() -> str:
    """æª¢æŸ¥ port 18789 ç‹€æ…‹ã€‚"""
    try:
        out = subprocess.run(
            ["lsof", "-i", f":{GATEWAY_PORT}"],
            capture_output=True,
            text=True,
            timeout=5,
        )
        if out.returncode != 0 or not out.stdout.strip():
            return f"port {GATEWAY_PORT} ç„¡é€²ç¨‹ä½”ç”¨"
        return f"port {GATEWAY_PORT}:\n{out.stdout.strip()}"
    except Exception as e:
        return f"æª¢æŸ¥å¤±æ•—: {e}"


def _list_services() -> str:
    """åˆ—å‡º openclawã€ollama ç›¸é—œ launchctl æœå‹™ã€‚"""
    try:
        out = subprocess.run(
            ["launchctl", "list"],
            capture_output=True,
            text=True,
            timeout=5,
        )
        lines = [l for l in out.stdout.splitlines() if "openclaw" in l.lower() or "ollama" in l.lower()]
        return "ç›¸é—œæœå‹™ï¼š\n" + ("\n".join(lines) if lines else "(ç„¡)")
    except Exception as e:
        return f"æŸ¥è©¢å¤±æ•—: {e}"


async def cmd_restart_openclaw(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """é‡å•Ÿ OpenClaw Gateway"""
    user = update.effective_user
    logger.info("æ”¶åˆ° /restart_openclaw from user_id=%s", user.id)
    if not _can_exec(user.id):
        await update.message.reply_text("âŒ ä½ æ²’æœ‰æ¬Šé™åŸ·è¡Œæ­¤æŒ‡ä»¤")
        return
    msg = await update.message.reply_text("â³ æ­£åœ¨å®Œæ•´é‡å•Ÿ OpenClaw Gateway...")
    ok, text = _do_restart_openclaw()
    await msg.edit_text(text)


async def cmd_restart_ollama(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    if not _can_exec(user.id):
        await update.message.reply_text("âŒ ä½ æ²’æœ‰æ¬Šé™åŸ·è¡Œæ­¤æŒ‡ä»¤")
        return
    msg = await update.message.reply_text("â³ æ­£åœ¨é‡å•Ÿ Ollama...")
    ok, text = _do_restart_ollama()
    await msg.edit_text(text)


async def cmd_gateway_logs(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    if not _can_exec(user.id):
        await update.message.reply_text("âŒ ä½ æ²’æœ‰æ¬Šé™åŸ·è¡Œæ­¤æŒ‡ä»¤")
        return
    txt = _get_gateway_logs()
    await update.message.reply_text(txt[:4000] + ("\n...(å·²æˆªæ–·)" if len(txt) > 4000 else ""))


async def cmd_check_port(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    if not _can_exec(user.id):
        await update.message.reply_text("âŒ ä½ æ²’æœ‰æ¬Šé™åŸ·è¡Œæ­¤æŒ‡ä»¤")
        return
    await update.message.reply_text(_check_port())


async def cmd_list_services(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    if not _can_exec(user.id):
        await update.message.reply_text("âŒ ä½ æ²’æœ‰æ¬Šé™åŸ·è¡Œæ­¤æŒ‡ä»¤")
        return
    await update.message.reply_text(_list_services())


async def cmd_help(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    txt = """ğŸ“‹ æŒ‡ä»¤åˆ—è¡¨

å°è©±ï¼š/startã€/statusã€/model
è¨˜æ†¶ï¼š/clear_memory
åŸ·è¡Œï¼ˆéœ€æ¬Šé™ï¼‰ï¼š
  /restart_openclawã€/restart_ollama
  /gateway_logsã€/check_portã€/list_servicesã€/bot_logs

æˆ–ä½¿ç”¨ä¸‹æ–¹æŒ‰éˆ•å¿«é€Ÿæ“ä½œã€‚"""
    await update.message.reply_text(txt)


async def cmd_clear_memory(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    _clear_memory(user.id)
    if "chat_history" in context.user_data:
        del context.user_data["chat_history"]
    await update.message.reply_text("âœ… å·²æ¸…é™¤ä½ çš„é•·æœŸè¨˜æ†¶èˆ‡å°è©±æ­·ç¨‹")


async def cmd_bot_logs(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    if not _can_exec(user.id):
        await update.message.reply_text("âŒ ä½ æ²’æœ‰æ¬Šé™åŸ·è¡Œæ­¤æŒ‡ä»¤")
        return
    try:
        out = subprocess.run(
            ["tail", "-n", "20", str(LOG_FILE)],
            capture_output=True,
            text=True,
            timeout=5,
        )
        txt = out.stdout.strip() or "(ç©ºç™½)"
        await update.message.reply_text(_truncate(txt))
    except Exception as e:
        await update.message.reply_text(f"è®€å–å¤±æ•—: {e}")


async def cmd_status(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    ok, msg = ollama_client.check_ollama_status()
    await update.message.reply_text(msg)


def main() -> None:
    if not TELEGRAM_BOT_TOKEN:
        print("è«‹åœ¨ ollama_bot2.env æˆ–ç’°å¢ƒè®Šæ•¸è¨­å®š TELEGRAM_BOT_TOKEN")
        print("ä¾‹: TELEGRAM_BOT_TOKEN=ä½ çš„ç¬¬äºŒå€‹æ©Ÿå™¨äºº token")
        return

    async def post_init(app):
        await app.bot.set_my_commands([
            ("start", "èªªæ˜"),
            ("help", "æŒ‡ä»¤åˆ—è¡¨"),
            ("status", "æŸ¥è©¢ Ollama ç‹€æ…‹"),
            ("model", "åˆ‡æ›æ¨¡å‹"),
            ("clear_memory", "æ¸…é™¤é•·æœŸè¨˜æ†¶"),
            ("restart_openclaw", "é‡å•Ÿ OpenClaw Gateway"),
            ("restart_ollama", "é‡å•Ÿ Ollama"),
            ("gateway_logs", "Gateway éŒ¯èª¤æ—¥èªŒ"),
            ("check_port", "æª¢æŸ¥ port 18789"),
            ("list_services", "åˆ—å‡ºç›¸é—œæœå‹™"),
            ("bot_logs", "Bot æ—¥èªŒï¼ˆæœ€å¾Œ 20 è¡Œï¼‰"),
        ])

    app = Application.builder().token(TELEGRAM_BOT_TOKEN).post_init(post_init).build()
    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("help", cmd_help))
    app.add_handler(CommandHandler("clear_memory", cmd_clear_memory))
    app.add_handler(CommandHandler("bot_logs", cmd_bot_logs))
    app.add_handler(CommandHandler("status", cmd_status))
    app.add_handler(CommandHandler("model", cmd_model))
    app.add_handler(CommandHandler("restart_openclaw", cmd_restart_openclaw))
    app.add_handler(CommandHandler("restart_ollama", cmd_restart_ollama))
    app.add_handler(CommandHandler("gateway_logs", cmd_gateway_logs))
    app.add_handler(CommandHandler("check_port", cmd_check_port))
    app.add_handler(CommandHandler("list_services", cmd_list_services))
    app.add_handler(CallbackQueryHandler(cb_model, pattern=r"^model:"))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_error_handler(error_handler)

    logger.info(
        "ollama_bot2 å•Ÿå‹• (Ollama: %s, é è¨­æ¨¡å‹: %s) æ—¥èªŒ: %s",
        ollama_client.OLLAMA_URL,
        ollama_client.OLLAMA_MODEL,
        LOG_FILE,
    )
    app.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    main()
